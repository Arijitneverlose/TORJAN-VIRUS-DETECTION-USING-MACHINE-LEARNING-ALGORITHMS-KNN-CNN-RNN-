{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1NS1cF1QuRpjM1vPeZFnanRvCsGh2_B8q",
      "authorship_tag": "ABX9TyPJC7CwpIf5jLeIWkaD2AMV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arijitneverlose/TORJAN-VIRUS-DETECTION-USING-MACHINE-LEARNING-ALGORITHMS-KNN-CNN-RNN-/blob/main/Copy_of_CNNALGORITHM2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfApH3RteccB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bb9b65e-0003-42d1-eb7a-b4572a781a25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "uS-DDC3L5HFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYTDyn8IqKfP",
        "outputId": "e55d7e33-caba-4805-a266-c5becfab55d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load your Trojan virus dataset from Excel\n",
        "# Replace 'your_dataset.xlsx' with the actual name of your Excel file\n",
        "df = pd.read_excel('/content/drive/MyDrive/data_4 (1).xlsx')\n",
        "# Drop the 'Circuit' column from the dataset\n",
        "df.drop(columns=['Circuit'], inplace=True)\n",
        "\n",
        "# Specify the target column for classification\n",
        "target_column = \"Label\"\n",
        "\n",
        "# Encode the target column using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "df[target_column] = label_encoder.fit_transform(df[target_column])\n",
        "\n",
        "# Separate target variable from the rest of the dataset\n",
        "X = df.drop(columns=[target_column])\n",
        "y = df[target_column]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "height = 100\n",
        "width = 100\n",
        "channels = 3  # For RGB images\n",
        "\n",
        "# Step 3: Define and compile the CNN model\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#  model training and evaluation\n",
        "model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n",
        "\n",
        "# Step 5: Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')"
      ],
      "metadata": {
        "id": "PoeV9Iraqgie",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "75632b15-91f0-4d32-cdd7-d2d41ee0a065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/data_4 (1).xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9d4a686faf6e>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load your Trojan virus dataset from Excel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Replace 'your_dataset.xlsx' with the actual name of your Excel file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/data_4 (1).xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# Drop the 'Circuit' column from the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Circuit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1494\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1497\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1372\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/data_4 (1).xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lQGLJjfnmWad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "teH3PSrOkkHI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29c276bf-bfb8-4ec7-f76b-bbbec40546ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define the CNN architecture\n",
        "def create_cnn(input_shape, num_classes):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "# Prepare data (assuming you have your data loaded into X_train, y_train, X_test, y_test)\n",
        "# Make sure your data is appropriately preprocessed and normalized\n",
        "\n",
        "# Define input shape and number of classes\n",
        "input_shape = (28, 28, 1)  # Example for MNIST dataset\n",
        "num_classes = 10  # Example for MNIST dataset\n",
        "\n",
        "# Create the CNN model\n",
        "model = create_cnn(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "bQKUx3tCJs5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i])\n",
        "    # The CIFAR labels happen to be arrays,\n",
        "    # which is why you need the extra index\n",
        "    plt.xlabel(class_names[train_labels[i][0]])\n",
        "plt.show()\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10))\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=10,\n",
        "                    validation_data=(test_images, test_labels))\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "HnzWpVxR1Otg",
        "outputId": "8b32c06e-95ae-4892-a60e-78fe59ce771b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-e1dc55fd0013>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                'dog', 'frog', 'horse', 'ship', 'truck']\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_excel('/content/drive/MyDrive/data_4 (1).xlsx')\n",
        "\n",
        "df.drop(columns=['Circuit'], inplace=True)\n",
        "\n",
        "\n",
        "target_column = \"Label\"\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df[target_column] = label_encoder.fit_transform(df[target_column])\n",
        "\n",
        "X = df.drop(columns=[target_column])\n",
        "y = df[target_column]\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = X_train.values.reshape(-1, 100, 100, 3)\n",
        "X_test = X_test.values.reshape(-1, 100, 100, 3)\n",
        "\n",
        "# Step 3: Define and compile the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Model training\n",
        "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n",
        "\n",
        "# Step 5: Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n",
        "# Plot training and validation accuracy over epochs+\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "c_0XZcpwImj8",
        "outputId": "bb5e1688-4851-4af2-c0cf-95d229bee18a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 7154 into shape (100,100,3)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bc4db52ee86b>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 7154 into shape (100,100,3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'X' contains numerical features and 'y' contains labels\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Reshape numerical features into image-like representations\n",
        "# Calculate the number of features per image\n",
        "num_features = X.shape[1]\n",
        "\n",
        "# Determine the size of each dimension based on the desired image shape\n",
        "image_size = int(np.sqrt(num_features))  # Assuming square images\n",
        "\n",
        "# Reshape the data into image-like representations\n",
        "X_images = X.values.reshape(-1, image_size, image_size, 1)  # Assuming grayscale images\n",
        "\n",
        "# Normalize pixel values to range [0, 1]\n",
        "X_images = X_images.astype('float32') / 255.0\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_images, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define and compile the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_size, image_size, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Model training\n",
        "model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "OQjJvZrEJ-f3",
        "outputId": "ccc6cea9-2ba9-4265-9942-0be15280c680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer \"conv2d_1\" (type Conv2D).\n\nNegative dimension size caused by subtracting 3 from 2 for '{{node conv2d_1/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_1/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,32], [3,3,32,64].\n\nCall arguments received by layer \"conv2d_1\" (type Conv2D):\n  • inputs=tf.Tensor(shape=(None, 2, 2, 32), dtype=float32)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-27f8525fcc74>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Define and compile the CNN model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m model = models.Sequential([\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1018\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;31m# Record the current Python stack trace as the creating stacktrace of this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"conv2d_1\" (type Conv2D).\n\nNegative dimension size caused by subtracting 3 from 2 for '{{node conv2d_1/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_1/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,32], [3,3,32,64].\n\nCall arguments received by layer \"conv2d_1\" (type Conv2D):\n  • inputs=tf.Tensor(shape=(None, 2, 2, 32), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Assuming 'X' contains numerical features and 'y' contains labels\n",
        "# Reshape numerical features into 2D \"images\"\n",
        "X_images = X.values.reshape(-1, 49, 1, 1)  # Reshape to (samples, width, height, channels)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_images, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define and compile the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 1), activation='relu', input_shape=(49, 1, 1)),\n",
        "    layers.MaxPooling2D((2, 1)),\n",
        "    layers.Conv2D(64, (3, 1), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 1)),\n",
        "    layers.Conv2D(64, (3, 1), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Model training\n",
        "model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "qb98a7CiRsiU",
        "outputId": "82c08319-2d8a-4f29-9e59-817a5320fa1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-48ed84a40908>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Assuming 'X' contains numerical features and 'y' contains labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Reshape numerical features into 2D \"images\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m49\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reshape to (samples, width, height, channels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Split the dataset into training and testing sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Custom accuracy function\n",
        "def custom_accuracy(y_true, y_pred):\n",
        "    y_pred_binary = tf.round(y_pred)\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(y_true, y_pred_binary), tf.float32))\n",
        "    return accuracy\n",
        "\n",
        "# Custom loss function\n",
        "def custom_loss(y_true, y_pred):\n",
        "    loss = -1 * tf.reduce_mean(y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred))\n",
        "    return loss\n",
        "\n",
        "# Assuming 'X' contains numerical features and 'y' contains labels\n",
        "X_images = X.values.reshape(-1, 49, 1, 1)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_images, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define and compile the CNN model with custom accuracy and loss functions\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 1), activation='relu', input_shape=(49, 1, 1)),\n",
        "    layers.MaxPooling2D((2, 1)),\n",
        "    layers.Conv2D(64, (3, 1), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 1)),\n",
        "    layers.Conv2D(64, (3, 1), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=custom_loss,\n",
        "              metrics=[custom_accuracy])\n",
        "\n",
        "# Model training\n",
        "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test loss: {test_loss}, Test accuracy: {test_accuracy}')\n",
        "\n",
        "# Print accuracy and loss before plotting\n",
        "print(\"Final Accuracy:\", history.history['accuracy'][-1])\n",
        "print(\"Final Validation Accuracy:\", history.history['val_accuracy'][-1])\n",
        "print(\"Final Loss:\", history.history['loss'][-1])\n",
        "print(\"Final Validation Loss:\", history.history['val_loss'][-1])\n",
        "\n",
        "# Plot training and validation accuracy over epochs\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation loss over epochs\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "dYJZn4qmV9SP",
        "outputId": "3aaaaf24-3049-490c-cf33-7a7eb8a3b18a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"<ipython-input-6-0b8e4925a001>\", line 15, in custom_loss  *\n        loss = -1 * tf.reduce_mean(y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred))\n\n    TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type int64 of argument 'x'.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0b8e4925a001>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Model training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filel7bs9hcp.py\u001b[0m in \u001b[0;36mtf__custom_loss\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"<ipython-input-6-0b8e4925a001>\", line 15, in custom_loss  *\n        loss = -1 * tf.reduce_mean(y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred))\n\n    TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type int64 of argument 'x'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Custom accuracy function\n",
        "def custom_accuracy(y_true, y_pred):\n",
        "    y_pred_binary = tf.round(y_pred)\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(y_true, y_pred_binary), tf.float32))\n",
        "    return accuracy\n",
        "\n",
        "# Custom loss function\n",
        "def custom_loss(y_true, y_pred):\n",
        "    loss = -1 * tf.reduce_mean(y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred))\n",
        "    return loss\n",
        "\n",
        "# Assuming 'X' contains numerical features and 'y' contains labels\n",
        "X_images = X.values.reshape(-1, 49, 1, 1)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_images, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define and compile the CNN model with custom accuracy and loss functions\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 1), activation='relu', input_shape=(49, 1, 1)),\n",
        "    layers.MaxPooling2D((2, 1)),\n",
        "    layers.Conv2D(64, (3, 1), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 1)),\n",
        "    layers.Conv2D(64, (3, 1), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=custom_loss,\n",
        "              metrics=[custom_accuracy])\n",
        "\n",
        "# Model training\n",
        "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test loss: {test_loss}, Test accuracy: {test_accuracy}')\n",
        "\n",
        "# Plot training and validation accuracy over epochs\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation loss over epochs\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "6I3wNgrWWMuI",
        "outputId": "ed2a0c06-9124-4ef7-fc50-1f5189eb42e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"<ipython-input-7-82d222d24902>\", line 14, in custom_loss  *\n        loss = -1 * tf.reduce_mean(y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred))\n\n    TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type int64 of argument 'x'.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-82d222d24902>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Model training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filejbr4673n.py\u001b[0m in \u001b[0;36mtf__custom_loss\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"<ipython-input-7-82d222d24902>\", line 14, in custom_loss  *\n        loss = -1 * tf.reduce_mean(y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred))\n\n    TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type int64 of argument 'x'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Assuming 'X' contains numerical features and 'y' contains labels\n",
        "# Reshape numerical features into 2D \"images\"\n",
        "X_images = X.values.reshape(-1, 49, 1, 1)  # Reshape to (samples, width, height, channels)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_images, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define and compile the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 1), activation='relu', input_shape=(49, 1, 1)),\n",
        "    layers.MaxPooling2D((2, 1)),\n",
        "    layers.Conv2D(64, (3, 1), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 1)),\n",
        "    layers.Conv2D(64, (3, 1), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Model training\n",
        "model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzOz8VCDWZS6",
        "outputId": "a5a9ebf9-2db2-4dbc-d3fe-2849d576fbfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 109ms/step - loss: 16.5074 - accuracy: 0.7534 - val_loss: 4.1416 - val_accuracy: 0.9730\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 12.9497 - accuracy: 0.9589 - val_loss: 4.8119 - val_accuracy: 0.9730\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 11.4925 - accuracy: 0.9589 - val_loss: 3.5004 - val_accuracy: 0.9730\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 6.7463 - accuracy: 0.9589 - val_loss: 1.8178 - val_accuracy: 0.9730\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 2.4254 - accuracy: 0.9178 - val_loss: 0.2582 - val_accuracy: 0.9730\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2826 - accuracy: 0.9452 - val_loss: 0.2505 - val_accuracy: 0.9730\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4165 - accuracy: 0.9315 - val_loss: 0.3281 - val_accuracy: 0.9730\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4797 - accuracy: 0.9315 - val_loss: 0.2215 - val_accuracy: 0.9730\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.4531 - accuracy: 0.9521 - val_loss: 0.2316 - val_accuracy: 0.9459\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.9550 - accuracy: 0.9041 - val_loss: 0.9072 - val_accuracy: 0.9730\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 2.3389 - accuracy: 0.9589 - val_loss: 0.9173 - val_accuracy: 0.9730\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 1.8058 - accuracy: 0.9589 - val_loss: 0.3624 - val_accuracy: 0.9730\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 1.6258 - accuracy: 0.7466 - val_loss: 0.8881 - val_accuracy: 0.9730\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 3.0642 - accuracy: 0.9589 - val_loss: 1.5544 - val_accuracy: 0.9730\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 3.5572 - accuracy: 0.9589 - val_loss: 1.2955 - val_accuracy: 0.9730\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 2.3767 - accuracy: 0.9589 - val_loss: 0.5763 - val_accuracy: 0.9730\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.9155 - accuracy: 0.8630 - val_loss: 0.3518 - val_accuracy: 0.9730\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.4864 - accuracy: 0.9589 - val_loss: 0.3352 - val_accuracy: 0.9730\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2766 - accuracy: 0.9452 - val_loss: 0.3088 - val_accuracy: 0.9459\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2655 - accuracy: 0.9521 - val_loss: 0.3378 - val_accuracy: 0.9730\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.2428 - accuracy: 0.9589 - val_loss: 1.3091 - val_accuracy: 0.6216\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 1.4762 - accuracy: 0.8699 - val_loss: 0.7656 - val_accuracy: 0.9730\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 1.5818 - accuracy: 0.9589 - val_loss: 0.6872 - val_accuracy: 0.9730\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.9220 - accuracy: 0.9589 - val_loss: 0.2737 - val_accuracy: 0.9459\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.7662 - accuracy: 0.8562 - val_loss: 0.4548 - val_accuracy: 0.9730\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6411 - accuracy: 0.9589 - val_loss: 0.2880 - val_accuracy: 0.9730\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5323 - accuracy: 0.8973 - val_loss: 0.3906 - val_accuracy: 0.9730\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6165 - accuracy: 0.9589 - val_loss: 0.4548 - val_accuracy: 0.9730\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.4938 - accuracy: 0.9589 - val_loss: 0.2873 - val_accuracy: 0.9459\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.3568 - accuracy: 0.9315 - val_loss: 0.2671 - val_accuracy: 0.9730\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.2894 - accuracy: 0.9521 - val_loss: 0.2396 - val_accuracy: 0.9730\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.2930 - accuracy: 0.9315 - val_loss: 0.2412 - val_accuracy: 0.9730\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.2598 - accuracy: 0.9521 - val_loss: 0.2193 - val_accuracy: 0.9730\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.2246 - accuracy: 0.9452 - val_loss: 0.1868 - val_accuracy: 0.9730\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.2076 - accuracy: 0.9384 - val_loss: 0.2040 - val_accuracy: 0.9730\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1600 - accuracy: 0.9589 - val_loss: 0.4070 - val_accuracy: 0.9189\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.2970 - accuracy: 0.9521 - val_loss: 0.2804 - val_accuracy: 0.9730\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3919 - accuracy: 0.9589 - val_loss: 0.1490 - val_accuracy: 0.9459\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4297 - accuracy: 0.9315 - val_loss: 0.2824 - val_accuracy: 0.9730\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4547 - accuracy: 0.9521 - val_loss: 0.1408 - val_accuracy: 0.9730\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1572 - accuracy: 0.9452 - val_loss: 0.1493 - val_accuracy: 0.9730\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1844 - accuracy: 0.9589 - val_loss: 0.2153 - val_accuracy: 0.9459\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1971 - accuracy: 0.9452 - val_loss: 0.1471 - val_accuracy: 0.9730\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1813 - accuracy: 0.9589 - val_loss: 0.1409 - val_accuracy: 0.9730\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4260 - accuracy: 0.8767 - val_loss: 0.4734 - val_accuracy: 0.9730\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 1.2055 - accuracy: 0.9589 - val_loss: 0.5114 - val_accuracy: 0.9730\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6435 - accuracy: 0.9589 - val_loss: 0.1537 - val_accuracy: 0.9730\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5729 - accuracy: 0.8904 - val_loss: 0.2935 - val_accuracy: 0.9730\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4952 - accuracy: 0.9589 - val_loss: 0.2362 - val_accuracy: 0.9730\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1823 - accuracy: 0.9384 - val_loss: 0.2096 - val_accuracy: 0.9730\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3601 - accuracy: 0.9589 - val_loss: 0.2577 - val_accuracy: 0.9730\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2071 - accuracy: 0.9521 - val_loss: 0.2507 - val_accuracy: 0.9459\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3753 - accuracy: 0.9452 - val_loss: 0.2851 - val_accuracy: 0.9730\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2945 - accuracy: 0.9521 - val_loss: 0.2894 - val_accuracy: 0.9189\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3406 - accuracy: 0.9589 - val_loss: 0.2991 - val_accuracy: 0.9730\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4238 - accuracy: 0.8767 - val_loss: 0.2397 - val_accuracy: 0.9730\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.8321 - accuracy: 0.9589 - val_loss: 0.6056 - val_accuracy: 0.9730\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3902 - accuracy: 0.9589 - val_loss: 0.4976 - val_accuracy: 0.9730\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6580 - accuracy: 0.9589 - val_loss: 0.1767 - val_accuracy: 0.9730\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2710 - accuracy: 0.9452 - val_loss: 0.2286 - val_accuracy: 0.9730\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2392 - accuracy: 0.9589 - val_loss: 0.2080 - val_accuracy: 0.9459\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6831 - accuracy: 0.8493 - val_loss: 0.4555 - val_accuracy: 0.9730\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.8637 - accuracy: 0.9589 - val_loss: 0.4026 - val_accuracy: 0.9730\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4723 - accuracy: 0.9521 - val_loss: 0.4524 - val_accuracy: 0.9189\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2477 - accuracy: 0.9452 - val_loss: 0.2668 - val_accuracy: 0.9730\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3364 - accuracy: 0.9589 - val_loss: 0.1799 - val_accuracy: 0.9730\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2181 - accuracy: 0.9384 - val_loss: 0.2035 - val_accuracy: 0.9730\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3942 - accuracy: 0.9589 - val_loss: 0.2347 - val_accuracy: 0.9730\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2805 - accuracy: 0.9521 - val_loss: 0.1645 - val_accuracy: 0.9730\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2404 - accuracy: 0.9589 - val_loss: 0.2359 - val_accuracy: 0.9730\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2642 - accuracy: 0.9589 - val_loss: 0.1584 - val_accuracy: 0.9459\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.1900 - accuracy: 0.9452 - val_loss: 0.1485 - val_accuracy: 0.9730\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2056 - accuracy: 0.9521 - val_loss: 0.1437 - val_accuracy: 0.9730\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1964 - accuracy: 0.9384 - val_loss: 0.1744 - val_accuracy: 0.9730\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2738 - accuracy: 0.9589 - val_loss: 0.1854 - val_accuracy: 0.9730\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2351 - accuracy: 0.9384 - val_loss: 0.1336 - val_accuracy: 0.9730\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2125 - accuracy: 0.9452 - val_loss: 0.1337 - val_accuracy: 0.9730\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1879 - accuracy: 0.9384 - val_loss: 0.1392 - val_accuracy: 0.9730\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1573 - accuracy: 0.9589 - val_loss: 0.1276 - val_accuracy: 0.9730\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1791 - accuracy: 0.9384 - val_loss: 0.1317 - val_accuracy: 0.9730\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1880 - accuracy: 0.9452 - val_loss: 0.1501 - val_accuracy: 0.9730\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1755 - accuracy: 0.9384 - val_loss: 0.1365 - val_accuracy: 0.9730\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2531 - accuracy: 0.9589 - val_loss: 0.1418 - val_accuracy: 0.9730\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1641 - accuracy: 0.9589 - val_loss: 0.1549 - val_accuracy: 0.9730\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1381 - accuracy: 0.9589 - val_loss: 0.2961 - val_accuracy: 0.9189\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1970 - accuracy: 0.9521 - val_loss: 0.1578 - val_accuracy: 0.9730\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1679 - accuracy: 0.9452 - val_loss: 0.1633 - val_accuracy: 0.9730\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3842 - accuracy: 0.9589 - val_loss: 0.2216 - val_accuracy: 0.9730\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2070 - accuracy: 0.9521 - val_loss: 0.1501 - val_accuracy: 0.9730\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1074 - accuracy: 0.9658 - val_loss: 0.1602 - val_accuracy: 0.9730\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2128 - accuracy: 0.9452 - val_loss: 0.1583 - val_accuracy: 0.9730\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.1831 - accuracy: 0.9658 - val_loss: 0.1485 - val_accuracy: 0.9730\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1398 - accuracy: 0.9521 - val_loss: 0.1540 - val_accuracy: 0.9730\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1430 - accuracy: 0.9589 - val_loss: 0.2318 - val_accuracy: 0.9459\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1380 - accuracy: 0.9521 - val_loss: 0.1612 - val_accuracy: 0.9730\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1799 - accuracy: 0.9521 - val_loss: 0.1386 - val_accuracy: 0.9730\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1552 - accuracy: 0.9521 - val_loss: 0.1493 - val_accuracy: 0.9459\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1428 - accuracy: 0.9452 - val_loss: 0.1372 - val_accuracy: 0.9730\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1322 - accuracy: 0.9452 - val_loss: 0.1360 - val_accuracy: 0.9730\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1478 - accuracy: 0.9521 - val_loss: 0.1378 - val_accuracy: 0.9730\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b142ee6f2e0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reshape numerical features into 2D \"images\"\n",
        "X_images = X.values.reshape(-1, 49, 1, 1)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_images, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define and compile the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 1), activation='relu', input_shape=(49, 1, 1)),\n",
        "    layers.MaxPooling2D((2, 1)),\n",
        "    layers.Conv2D(64, (3, 1), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 1)),\n",
        "    layers.Conv2D(64, (3, 1), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Model training\n",
        "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n",
        "\n",
        "# Print accuracy and loss\n",
        "print(\"Training accuracy:\", history.history['accuracy'][-1])\n",
        "print(\"Training loss:\", history.history['loss'][-1])\n",
        "print(\"Validation accuracy:\", history.history['val_accuracy'][-1])\n",
        "print(\"Validation loss:\", history.history['val_loss'][-1])\n",
        "\n",
        "# Plot accuracy\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot loss\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "11WgeEc3WyhS",
        "outputId": "97cd66cd-0585-4271-b7f3-8fb5ec0d46f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 65ms/step - loss: 17.0983 - accuracy: 0.7534 - val_loss: 4.0335 - val_accuracy: 0.9730\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 10.7542 - accuracy: 0.9589 - val_loss: 3.7263 - val_accuracy: 0.9730\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 8.1153 - accuracy: 0.9589 - val_loss: 2.1347 - val_accuracy: 0.9730\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.9105 - accuracy: 0.9589 - val_loss: 0.4471 - val_accuracy: 0.9459\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.8791 - accuracy: 0.9041 - val_loss: 1.1615 - val_accuracy: 0.9730\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 2.6499 - accuracy: 0.9589 - val_loss: 1.5582 - val_accuracy: 0.9730\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 3.3512 - accuracy: 0.9589 - val_loss: 1.2241 - val_accuracy: 0.9730\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.7554 - accuracy: 0.9589 - val_loss: 0.4824 - val_accuracy: 0.9730\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.0502 - accuracy: 0.8836 - val_loss: 0.6730 - val_accuracy: 0.9730\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 1.1744 - accuracy: 0.9589 - val_loss: 0.8127 - val_accuracy: 0.9730\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 1.1994 - accuracy: 0.9589 - val_loss: 0.4870 - val_accuracy: 0.9730\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5196 - accuracy: 0.8699 - val_loss: 0.6560 - val_accuracy: 0.9730\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.4420 - accuracy: 0.9589 - val_loss: 1.0492 - val_accuracy: 0.9730\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.8774 - accuracy: 0.9589 - val_loss: 0.7627 - val_accuracy: 0.9730\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5739 - accuracy: 0.9384 - val_loss: 0.6538 - val_accuracy: 0.9189\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4327 - accuracy: 0.9521 - val_loss: 0.6930 - val_accuracy: 0.9730\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 1.0745 - accuracy: 0.9589 - val_loss: 0.5790 - val_accuracy: 0.9730\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6666 - accuracy: 0.9247 - val_loss: 0.3828 - val_accuracy: 0.9459\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.4451 - accuracy: 0.9589 - val_loss: 0.6999 - val_accuracy: 0.9730\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 1.2431 - accuracy: 0.9589 - val_loss: 0.5568 - val_accuracy: 0.9730\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.3752 - accuracy: 0.9589 - val_loss: 0.5403 - val_accuracy: 0.9189\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.5502 - accuracy: 0.9247 - val_loss: 0.5010 - val_accuracy: 0.9730\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.7835 - accuracy: 0.9589 - val_loss: 0.4024 - val_accuracy: 0.9730\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.4445 - accuracy: 0.9247 - val_loss: 0.3121 - val_accuracy: 0.9459\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4231 - accuracy: 0.9589 - val_loss: 0.3687 - val_accuracy: 0.9730\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3149 - accuracy: 0.9521 - val_loss: 0.2403 - val_accuracy: 0.9459\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.1784 - accuracy: 0.9589 - val_loss: 0.2432 - val_accuracy: 0.9730\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.2137 - accuracy: 0.9521 - val_loss: 0.1698 - val_accuracy: 0.9730\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.2532 - accuracy: 0.9384 - val_loss: 0.2765 - val_accuracy: 0.9730\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3298 - accuracy: 0.9589 - val_loss: 0.8840 - val_accuracy: 0.6216\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 1.3798 - accuracy: 0.8699 - val_loss: 0.7122 - val_accuracy: 0.9730\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.7038 - accuracy: 0.9589 - val_loss: 0.6322 - val_accuracy: 0.9730\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 1.0659 - accuracy: 0.9589 - val_loss: 0.1969 - val_accuracy: 0.9730\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.4452 - accuracy: 0.8630 - val_loss: 0.6102 - val_accuracy: 0.9730\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.5450 - accuracy: 0.9589 - val_loss: 0.8458 - val_accuracy: 0.9730\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 1.9262 - accuracy: 0.9589 - val_loss: 0.7041 - val_accuracy: 0.9730\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.1440 - accuracy: 0.9589 - val_loss: 0.2724 - val_accuracy: 0.9730\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.7616 - accuracy: 0.8425 - val_loss: 0.5396 - val_accuracy: 0.9730\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 1.4695 - accuracy: 0.9589 - val_loss: 0.8082 - val_accuracy: 0.9730\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 1.6867 - accuracy: 0.9589 - val_loss: 0.6466 - val_accuracy: 0.9730\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 1.1113 - accuracy: 0.9589 - val_loss: 0.2402 - val_accuracy: 0.9730\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6012 - accuracy: 0.8562 - val_loss: 0.4036 - val_accuracy: 0.9730\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.9799 - accuracy: 0.9589 - val_loss: 0.4872 - val_accuracy: 0.9730\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6312 - accuracy: 0.9589 - val_loss: 0.2535 - val_accuracy: 0.9459\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3989 - accuracy: 0.8836 - val_loss: 0.3643 - val_accuracy: 0.9730\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.6696 - accuracy: 0.9589 - val_loss: 0.4235 - val_accuracy: 0.9730\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5905 - accuracy: 0.9589 - val_loss: 0.2828 - val_accuracy: 0.9730\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4384 - accuracy: 0.8767 - val_loss: 0.2453 - val_accuracy: 0.9730\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3536 - accuracy: 0.9589 - val_loss: 0.3309 - val_accuracy: 0.9730\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.4064 - accuracy: 0.9589 - val_loss: 0.2196 - val_accuracy: 0.9730\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3131 - accuracy: 0.9178 - val_loss: 0.2141 - val_accuracy: 0.9730\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1866 - accuracy: 0.9589 - val_loss: 0.2344 - val_accuracy: 0.9730\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2305 - accuracy: 0.9384 - val_loss: 0.1802 - val_accuracy: 0.9730\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1766 - accuracy: 0.9315 - val_loss: 0.1655 - val_accuracy: 0.9730\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1929 - accuracy: 0.9384 - val_loss: 0.1626 - val_accuracy: 0.9459\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1767 - accuracy: 0.9384 - val_loss: 0.1880 - val_accuracy: 0.9730\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3981 - accuracy: 0.9589 - val_loss: 0.2068 - val_accuracy: 0.9730\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1879 - accuracy: 0.9589 - val_loss: 0.1445 - val_accuracy: 0.9730\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3931 - accuracy: 0.9521 - val_loss: 0.1909 - val_accuracy: 0.9730\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1694 - accuracy: 0.9384 - val_loss: 0.1527 - val_accuracy: 0.9730\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1483 - accuracy: 0.9452 - val_loss: 0.1489 - val_accuracy: 0.9459\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1333 - accuracy: 0.9521 - val_loss: 0.1645 - val_accuracy: 0.9730\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1616 - accuracy: 0.9589 - val_loss: 0.2674 - val_accuracy: 0.9189\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2680 - accuracy: 0.9521 - val_loss: 0.1749 - val_accuracy: 0.9730\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1600 - accuracy: 0.9521 - val_loss: 0.3177 - val_accuracy: 0.9189\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2189 - accuracy: 0.9521 - val_loss: 0.1876 - val_accuracy: 0.9730\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2434 - accuracy: 0.9315 - val_loss: 0.1662 - val_accuracy: 0.9730\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1961 - accuracy: 0.9658 - val_loss: 0.1907 - val_accuracy: 0.9730\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1288 - accuracy: 0.9658 - val_loss: 0.1961 - val_accuracy: 0.9459\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1084 - accuracy: 0.9521 - val_loss: 0.1876 - val_accuracy: 0.9730\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2942 - accuracy: 0.9589 - val_loss: 0.1770 - val_accuracy: 0.9730\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3784 - accuracy: 0.8630 - val_loss: 0.2699 - val_accuracy: 0.9730\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5482 - accuracy: 0.9589 - val_loss: 0.3369 - val_accuracy: 0.9730\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5560 - accuracy: 0.9589 - val_loss: 0.2137 - val_accuracy: 0.9730\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3162 - accuracy: 0.9247 - val_loss: 0.1674 - val_accuracy: 0.9730\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2006 - accuracy: 0.9658 - val_loss: 0.2230 - val_accuracy: 0.9730\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.2131 - accuracy: 0.9521 - val_loss: 0.1697 - val_accuracy: 0.9459\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1801 - accuracy: 0.9315 - val_loss: 0.1807 - val_accuracy: 0.9730\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2049 - accuracy: 0.9589 - val_loss: 0.2011 - val_accuracy: 0.9730\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2006 - accuracy: 0.9521 - val_loss: 0.1861 - val_accuracy: 0.9459\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1573 - accuracy: 0.9452 - val_loss: 0.1572 - val_accuracy: 0.9730\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1807 - accuracy: 0.9452 - val_loss: 0.1458 - val_accuracy: 0.9730\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1148 - accuracy: 0.9521 - val_loss: 0.1642 - val_accuracy: 0.9730\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.1606 - accuracy: 0.9452 - val_loss: 0.1504 - val_accuracy: 0.9730\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1386 - accuracy: 0.9589 - val_loss: 0.1481 - val_accuracy: 0.9730\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1157 - accuracy: 0.9452 - val_loss: 0.1530 - val_accuracy: 0.9730\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1371 - accuracy: 0.9384 - val_loss: 0.1632 - val_accuracy: 0.9730\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1259 - accuracy: 0.9589 - val_loss: 0.1724 - val_accuracy: 0.9459\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1375 - accuracy: 0.9452 - val_loss: 0.1592 - val_accuracy: 0.9730\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1746 - accuracy: 0.9384 - val_loss: 0.1521 - val_accuracy: 0.9730\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1341 - accuracy: 0.9521 - val_loss: 0.1439 - val_accuracy: 0.9730\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1154 - accuracy: 0.9452 - val_loss: 0.1423 - val_accuracy: 0.9730\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1419 - accuracy: 0.9589 - val_loss: 0.1723 - val_accuracy: 0.9459\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1658 - accuracy: 0.9452 - val_loss: 0.1739 - val_accuracy: 0.9730\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1375 - accuracy: 0.9589 - val_loss: 0.1324 - val_accuracy: 0.9730\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1333 - accuracy: 0.9589 - val_loss: 0.1340 - val_accuracy: 0.9730\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1584 - accuracy: 0.9315 - val_loss: 0.1921 - val_accuracy: 0.9730\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3115 - accuracy: 0.9589 - val_loss: 0.2286 - val_accuracy: 0.9730\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1446 - accuracy: 0.9521 - val_loss: 0.1805 - val_accuracy: 0.9459\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1316 - accuracy: 0.9589 - val_loss: 0.1826 - val_accuracy: 0.9730\n",
            "Training accuracy: 0.9589040875434875\n",
            "Training loss: 0.131627157330513\n",
            "Validation accuracy: 0.9729729890823364\n",
            "Validation loss: 0.18257978558540344\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vOJEeM1AGeiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load your Trojan virus dataset from Excel\n",
        "# Replace 'your_dataset.xlsx' with the actual name of your Excel file\n",
        "df = pd.read_excel('/content/drive/MyDrive/data_4 (1).xlsx')\n",
        "# Drop the 'Circuit' column from the dataset\n",
        "df.drop(columns=['Circuit'], inplace=True)\n",
        "\n",
        "# Specify the target column for classification\n",
        "target_column = \"Label\"\n",
        "\n",
        "# Encode the target column using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "df[target_column] = label_encoder.fit_transform(df[target_column])\n",
        "\n",
        "# Separate target variable from the rest of the dataset\n",
        "X = df.drop(columns=[target_column])\n",
        "y = df[target_column]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "height = 100\n",
        "width = 100\n",
        "channels = 3  # For RGB images\n",
        "\n",
        "# Step 3: Define and compile the CNN model\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#  model training and evaluation\n",
        "model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n",
        "\n",
        "# Step 5: Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uxlL9Z6mYr9",
        "outputId": "10c28567-8121-4f41-91f1-0152b79faf49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 84ms/step - loss: 15.1581 - accuracy: 0.9589 - val_loss: 7.4807 - val_accuracy: 0.9730\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 11.8642 - accuracy: 0.9589 - val_loss: 6.5715 - val_accuracy: 0.9730\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 9.8583 - accuracy: 0.9589 - val_loss: 5.4834 - val_accuracy: 0.9730\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 6.6361 - accuracy: 0.9589 - val_loss: 4.4918 - val_accuracy: 0.9730\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 4.2184 - accuracy: 0.9521 - val_loss: 3.6389 - val_accuracy: 0.9730\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 3.4747 - accuracy: 0.9452 - val_loss: 3.1660 - val_accuracy: 0.9730\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 3.5921 - accuracy: 0.9384 - val_loss: 3.0508 - val_accuracy: 0.9459\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 3.9891 - accuracy: 0.9315 - val_loss: 2.8946 - val_accuracy: 0.9730\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 3.3500 - accuracy: 0.9521 - val_loss: 3.1701 - val_accuracy: 0.9730\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 3.5751 - accuracy: 0.9452 - val_loss: 3.2761 - val_accuracy: 0.9730\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 3.6838 - accuracy: 0.9452 - val_loss: 3.1809 - val_accuracy: 0.9730\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.5949 - accuracy: 0.9452 - val_loss: 3.0610 - val_accuracy: 0.9730\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 3.5372 - accuracy: 0.9452 - val_loss: 3.0434 - val_accuracy: 0.9730\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 3.5908 - accuracy: 0.9452 - val_loss: 2.8593 - val_accuracy: 0.9730\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 3.4325 - accuracy: 0.9452 - val_loss: 2.8441 - val_accuracy: 0.9730\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 3.3881 - accuracy: 0.9384 - val_loss: 2.9708 - val_accuracy: 0.9730\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 3.4210 - accuracy: 0.9452 - val_loss: 2.8223 - val_accuracy: 0.9730\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 3.3711 - accuracy: 0.9452 - val_loss: 2.9032 - val_accuracy: 0.9730\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 3.3557 - accuracy: 0.9452 - val_loss: 2.8566 - val_accuracy: 0.9730\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 3.3269 - accuracy: 0.9452 - val_loss: 2.7581 - val_accuracy: 0.9730\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 3.3733 - accuracy: 0.9521 - val_loss: 2.8608 - val_accuracy: 0.9730\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 3.2588 - accuracy: 0.9452 - val_loss: 2.7001 - val_accuracy: 0.9730\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 3.3580 - accuracy: 0.9452 - val_loss: 2.7139 - val_accuracy: 0.9730\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 3.2515 - accuracy: 0.9452 - val_loss: 2.9107 - val_accuracy: 0.9730\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 3.3972 - accuracy: 0.9452 - val_loss: 2.9604 - val_accuracy: 0.9730\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 3.3298 - accuracy: 0.9452 - val_loss: 2.6975 - val_accuracy: 0.9730\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 3.4197 - accuracy: 0.9384 - val_loss: 2.6065 - val_accuracy: 0.9730\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 3.2317 - accuracy: 0.9384 - val_loss: 2.8794 - val_accuracy: 0.9730\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 3.3046 - accuracy: 0.9452 - val_loss: 2.9863 - val_accuracy: 0.9730\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 3.3165 - accuracy: 0.9452 - val_loss: 2.8206 - val_accuracy: 0.9730\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.1890 - accuracy: 0.9452 - val_loss: 2.7026 - val_accuracy: 0.9730\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 3.1031 - accuracy: 0.9452 - val_loss: 2.6367 - val_accuracy: 0.9730\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 3.0736 - accuracy: 0.9452 - val_loss: 2.4957 - val_accuracy: 0.9730\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 3.1293 - accuracy: 0.9384 - val_loss: 2.5518 - val_accuracy: 0.9730\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 3.0775 - accuracy: 0.9521 - val_loss: 2.8206 - val_accuracy: 0.9730\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.2131 - accuracy: 0.9452 - val_loss: 2.8728 - val_accuracy: 0.9730\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 3.1848 - accuracy: 0.9452 - val_loss: 2.7122 - val_accuracy: 0.9730\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 3.0938 - accuracy: 0.9452 - val_loss: 2.5199 - val_accuracy: 0.9730\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.9805 - accuracy: 0.9452 - val_loss: 2.5044 - val_accuracy: 0.9730\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.9588 - accuracy: 0.9521 - val_loss: 2.4777 - val_accuracy: 0.9730\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.9535 - accuracy: 0.9452 - val_loss: 2.3866 - val_accuracy: 0.9730\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.9328 - accuracy: 0.9452 - val_loss: 2.4901 - val_accuracy: 0.9730\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.9068 - accuracy: 0.9452 - val_loss: 2.4725 - val_accuracy: 0.9730\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.8730 - accuracy: 0.9452 - val_loss: 2.4047 - val_accuracy: 0.9730\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.8479 - accuracy: 0.9452 - val_loss: 2.4401 - val_accuracy: 0.9730\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.9501 - accuracy: 0.9384 - val_loss: 2.4066 - val_accuracy: 0.9730\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.0104 - accuracy: 0.9452 - val_loss: 2.4804 - val_accuracy: 0.9730\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.8003 - accuracy: 0.9452 - val_loss: 2.2668 - val_accuracy: 0.9730\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.9277 - accuracy: 0.9452 - val_loss: 2.2619 - val_accuracy: 0.9730\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.8366 - accuracy: 0.9452 - val_loss: 2.4763 - val_accuracy: 0.9730\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.8775 - accuracy: 0.9452 - val_loss: 2.5279 - val_accuracy: 0.9730\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.8566 - accuracy: 0.9452 - val_loss: 2.3991 - val_accuracy: 0.9730\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.6976 - accuracy: 0.9452 - val_loss: 2.2599 - val_accuracy: 0.9730\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.7890 - accuracy: 0.9315 - val_loss: 2.1786 - val_accuracy: 0.9730\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.7957 - accuracy: 0.9384 - val_loss: 2.3463 - val_accuracy: 0.9730\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.7136 - accuracy: 0.9452 - val_loss: 2.2344 - val_accuracy: 0.9730\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.8498 - accuracy: 0.9315 - val_loss: 2.1056 - val_accuracy: 0.9730\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.8269 - accuracy: 0.9315 - val_loss: 2.3710 - val_accuracy: 0.9730\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.7270 - accuracy: 0.9452 - val_loss: 2.3849 - val_accuracy: 0.9730\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.6670 - accuracy: 0.9452 - val_loss: 2.2396 - val_accuracy: 0.9730\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 2.6601 - accuracy: 0.9452 - val_loss: 2.0232 - val_accuracy: 0.9459\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 2.6646 - accuracy: 0.9384 - val_loss: 2.1098 - val_accuracy: 0.9730\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.5980 - accuracy: 0.9452 - val_loss: 2.2358 - val_accuracy: 0.9730\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.5865 - accuracy: 0.9452 - val_loss: 2.1197 - val_accuracy: 0.9730\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.4993 - accuracy: 0.9452 - val_loss: 2.0944 - val_accuracy: 0.9730\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.6194 - accuracy: 0.9452 - val_loss: 2.1152 - val_accuracy: 0.9730\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.4814 - accuracy: 0.9452 - val_loss: 1.9980 - val_accuracy: 0.9730\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.5714 - accuracy: 0.9384 - val_loss: 1.9144 - val_accuracy: 0.9730\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.4303 - accuracy: 0.9452 - val_loss: 2.1593 - val_accuracy: 0.9730\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 2.4781 - accuracy: 0.9452 - val_loss: 2.1528 - val_accuracy: 0.9730\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.5770 - accuracy: 0.9452 - val_loss: 1.9935 - val_accuracy: 0.9730\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.4655 - accuracy: 0.9452 - val_loss: 2.0472 - val_accuracy: 0.9730\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.4456 - accuracy: 0.9452 - val_loss: 2.0598 - val_accuracy: 0.9730\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.3855 - accuracy: 0.9452 - val_loss: 1.9528 - val_accuracy: 0.9730\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.5584 - accuracy: 0.9452 - val_loss: 1.8047 - val_accuracy: 0.9730\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.2642 - accuracy: 0.9384 - val_loss: 2.0043 - val_accuracy: 0.9730\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.3563 - accuracy: 0.9452 - val_loss: 2.1772 - val_accuracy: 0.9730\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.5363 - accuracy: 0.9452 - val_loss: 2.2195 - val_accuracy: 0.9730\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.4295 - accuracy: 0.9452 - val_loss: 1.9762 - val_accuracy: 0.9730\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.2412 - accuracy: 0.9452 - val_loss: 1.8142 - val_accuracy: 0.9730\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.3150 - accuracy: 0.9452 - val_loss: 1.7663 - val_accuracy: 0.9730\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.2086 - accuracy: 0.9452 - val_loss: 1.8403 - val_accuracy: 0.9730\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.2026 - accuracy: 0.9452 - val_loss: 1.8082 - val_accuracy: 0.9730\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.2860 - accuracy: 0.9452 - val_loss: 1.7020 - val_accuracy: 0.9730\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.1555 - accuracy: 0.9452 - val_loss: 1.7983 - val_accuracy: 0.9730\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 2.3363 - accuracy: 0.9452 - val_loss: 1.9603 - val_accuracy: 0.9730\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.1983 - accuracy: 0.9452 - val_loss: 1.8457 - val_accuracy: 0.9730\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.3025 - accuracy: 0.9315 - val_loss: 1.6422 - val_accuracy: 0.9459\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.3100 - accuracy: 0.9384 - val_loss: 1.7261 - val_accuracy: 0.9730\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.0530 - accuracy: 0.9452 - val_loss: 1.8814 - val_accuracy: 0.9730\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.1403 - accuracy: 0.9452 - val_loss: 2.0216 - val_accuracy: 0.9730\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.2762 - accuracy: 0.9452 - val_loss: 2.1451 - val_accuracy: 0.9730\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 2.2957 - accuracy: 0.9452 - val_loss: 2.0112 - val_accuracy: 0.9730\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.1621 - accuracy: 0.9452 - val_loss: 1.7466 - val_accuracy: 0.9730\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.3153 - accuracy: 0.9315 - val_loss: 1.4703 - val_accuracy: 0.9459\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 2.0351 - accuracy: 0.9315 - val_loss: 1.6371 - val_accuracy: 0.9730\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.9563 - accuracy: 0.9452 - val_loss: 1.7236 - val_accuracy: 0.9730\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.1243 - accuracy: 0.9452 - val_loss: 1.7512 - val_accuracy: 0.9730\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.9755 - accuracy: 0.9452 - val_loss: 1.6349 - val_accuracy: 0.9730\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.0778 - accuracy: 0.9384 - val_loss: 1.4060 - val_accuracy: 0.9730\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4060 - accuracy: 0.9730\n",
            "Test accuracy: 0.9729729890823364\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 49ms/step - loss: 2.1970 - accuracy: 0.9452 - val_loss: 1.5217 - val_accuracy: 0.9730\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 2.1457 - accuracy: 0.9452 - val_loss: 1.4315 - val_accuracy: 0.9730\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.8491 - accuracy: 0.9521 - val_loss: 1.5660 - val_accuracy: 0.9730\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.8896 - accuracy: 0.9452 - val_loss: 1.5557 - val_accuracy: 0.9730\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.9391 - accuracy: 0.9452 - val_loss: 1.4296 - val_accuracy: 0.9730\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8192 - accuracy: 0.9452 - val_loss: 1.4834 - val_accuracy: 0.9730\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7576 - accuracy: 0.9452 - val_loss: 1.5455 - val_accuracy: 0.9730\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.8874 - accuracy: 0.9452 - val_loss: 1.6913 - val_accuracy: 0.9730\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.9382 - accuracy: 0.9452 - val_loss: 1.6213 - val_accuracy: 0.9730\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.9181 - accuracy: 0.9452 - val_loss: 1.6590 - val_accuracy: 0.9730\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.8056 - accuracy: 0.9452 - val_loss: 1.5248 - val_accuracy: 0.9730\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8035 - accuracy: 0.9452 - val_loss: 1.2382 - val_accuracy: 0.9730\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8712 - accuracy: 0.9384 - val_loss: 1.3743 - val_accuracy: 0.9730\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.6930 - accuracy: 0.9452 - val_loss: 1.4064 - val_accuracy: 0.9730\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.6826 - accuracy: 0.9452 - val_loss: 1.3652 - val_accuracy: 0.9730\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.6577 - accuracy: 0.9452 - val_loss: 1.3028 - val_accuracy: 0.9730\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.9410 - accuracy: 0.9315 - val_loss: 1.2948 - val_accuracy: 0.9730\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6319 - accuracy: 0.9452 - val_loss: 1.4856 - val_accuracy: 0.9730\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.6989 - accuracy: 0.9452 - val_loss: 1.4929 - val_accuracy: 0.9730\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.7104 - accuracy: 0.9452 - val_loss: 1.4461 - val_accuracy: 0.9730\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5845 - accuracy: 0.9452 - val_loss: 1.2809 - val_accuracy: 0.9730\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5516 - accuracy: 0.9521 - val_loss: 1.1296 - val_accuracy: 0.9730\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.8803 - accuracy: 0.9384 - val_loss: 1.2422 - val_accuracy: 0.9730\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.6172 - accuracy: 0.9589 - val_loss: 1.4786 - val_accuracy: 0.9730\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.7999 - accuracy: 0.9521 - val_loss: 1.5394 - val_accuracy: 0.9730\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.7507 - accuracy: 0.9452 - val_loss: 1.3262 - val_accuracy: 0.9730\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5727 - accuracy: 0.9521 - val_loss: 1.1848 - val_accuracy: 0.9730\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5391 - accuracy: 0.9452 - val_loss: 1.2591 - val_accuracy: 0.9730\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.5516 - accuracy: 0.9452 - val_loss: 1.4077 - val_accuracy: 0.9730\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.6265 - accuracy: 0.9452 - val_loss: 1.3219 - val_accuracy: 0.9730\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5340 - accuracy: 0.9452 - val_loss: 1.2131 - val_accuracy: 0.9730\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.4633 - accuracy: 0.9452 - val_loss: 1.1256 - val_accuracy: 0.9730\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5239 - accuracy: 0.9384 - val_loss: 1.1779 - val_accuracy: 0.9730\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.4537 - accuracy: 0.9521 - val_loss: 1.2645 - val_accuracy: 0.9730\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.5022 - accuracy: 0.9452 - val_loss: 1.3181 - val_accuracy: 0.9730\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.4683 - accuracy: 0.9452 - val_loss: 1.2148 - val_accuracy: 0.9730\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.8106 - accuracy: 0.9315 - val_loss: 0.9570 - val_accuracy: 0.9730\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7114 - accuracy: 0.9315 - val_loss: 1.2907 - val_accuracy: 0.9730\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5448 - accuracy: 0.9589 - val_loss: 1.2985 - val_accuracy: 0.9730\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.3995 - accuracy: 0.9452 - val_loss: 1.1100 - val_accuracy: 0.9730\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.5668 - accuracy: 0.9384 - val_loss: 1.0472 - val_accuracy: 0.9730\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.4059 - accuracy: 0.9658 - val_loss: 1.3086 - val_accuracy: 0.9730\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.4764 - accuracy: 0.9589 - val_loss: 1.1460 - val_accuracy: 0.9730\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.3470 - accuracy: 0.9452 - val_loss: 0.9425 - val_accuracy: 0.9730\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.6313 - accuracy: 0.9384 - val_loss: 0.9845 - val_accuracy: 0.9730\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.3489 - accuracy: 0.9315 - val_loss: 1.3317 - val_accuracy: 0.9730\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.6011 - accuracy: 0.9589 - val_loss: 1.1587 - val_accuracy: 0.9730\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.4087 - accuracy: 0.9452 - val_loss: 0.9110 - val_accuracy: 0.9730\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 1.5274 - accuracy: 0.9384 - val_loss: 1.0277 - val_accuracy: 0.9730\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.4197 - accuracy: 0.9384 - val_loss: 1.2130 - val_accuracy: 0.9730\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.4304 - accuracy: 0.9452 - val_loss: 1.1172 - val_accuracy: 0.9730\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.3552 - accuracy: 0.9452 - val_loss: 1.0602 - val_accuracy: 0.9730\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4083 - accuracy: 0.9452 - val_loss: 1.0165 - val_accuracy: 0.9730\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4810 - accuracy: 0.9452 - val_loss: 1.1491 - val_accuracy: 0.9730\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.3286 - accuracy: 0.9452 - val_loss: 1.0213 - val_accuracy: 0.9730\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.5066 - accuracy: 0.9384 - val_loss: 0.9797 - val_accuracy: 0.9730\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.2660 - accuracy: 0.9452 - val_loss: 1.1003 - val_accuracy: 0.9730\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3427 - accuracy: 0.9658 - val_loss: 1.0947 - val_accuracy: 0.9730\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2844 - accuracy: 0.9452 - val_loss: 1.0618 - val_accuracy: 0.9730\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.2546 - accuracy: 0.9452 - val_loss: 0.9750 - val_accuracy: 0.9730\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2919 - accuracy: 0.9452 - val_loss: 0.9217 - val_accuracy: 0.9730\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.2610 - accuracy: 0.9452 - val_loss: 0.9985 - val_accuracy: 0.9730\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2737 - accuracy: 0.9452 - val_loss: 1.0854 - val_accuracy: 0.9730\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2591 - accuracy: 0.9589 - val_loss: 0.9569 - val_accuracy: 0.9730\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.2762 - accuracy: 0.9452 - val_loss: 0.8229 - val_accuracy: 0.9730\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.3847 - accuracy: 0.9384 - val_loss: 0.9200 - val_accuracy: 0.9730\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2797 - accuracy: 0.9452 - val_loss: 1.0280 - val_accuracy: 0.9730\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1.2926 - accuracy: 0.9521 - val_loss: 0.9036 - val_accuracy: 0.9730\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.2632 - accuracy: 0.9452 - val_loss: 0.9438 - val_accuracy: 0.9730\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 1.2077 - accuracy: 0.9521 - val_loss: 1.0329 - val_accuracy: 0.9730\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 1.1997 - accuracy: 0.9452 - val_loss: 0.9079 - val_accuracy: 0.9730\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 1.2606 - accuracy: 0.9452 - val_loss: 0.9130 - val_accuracy: 0.9730\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2584 - accuracy: 0.9452 - val_loss: 0.8840 - val_accuracy: 0.9730\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.2631 - accuracy: 0.9384 - val_loss: 0.8696 - val_accuracy: 0.9730\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.2604 - accuracy: 0.9452 - val_loss: 0.8618 - val_accuracy: 0.9730\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 1.1867 - accuracy: 0.9452 - val_loss: 0.9411 - val_accuracy: 0.9730\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.1716 - accuracy: 0.9452 - val_loss: 0.9583 - val_accuracy: 0.9730\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 1.1866 - accuracy: 0.9452 - val_loss: 0.9025 - val_accuracy: 0.9730\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 1.2034 - accuracy: 0.9452 - val_loss: 0.9332 - val_accuracy: 0.9730\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1.3790 - accuracy: 0.9521 - val_loss: 0.7672 - val_accuracy: 0.9730\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 1.2417 - accuracy: 0.9384 - val_loss: 0.9017 - val_accuracy: 0.9730\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1.2675 - accuracy: 0.9589 - val_loss: 1.1339 - val_accuracy: 0.9730\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 1.4861 - accuracy: 0.9726 - val_loss: 0.8773 - val_accuracy: 0.9730\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 1.0699 - accuracy: 0.9521 - val_loss: 0.7339 - val_accuracy: 0.9730\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.2519 - accuracy: 0.9384 - val_loss: 0.8587 - val_accuracy: 0.9730\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 1.1931 - accuracy: 0.9452 - val_loss: 0.9242 - val_accuracy: 0.9730\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 1.1339 - accuracy: 0.9521 - val_loss: 0.8249 - val_accuracy: 0.9730\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 1.1079 - accuracy: 0.9452 - val_loss: 0.7740 - val_accuracy: 0.9730\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 1.1228 - accuracy: 0.9521 - val_loss: 0.8271 - val_accuracy: 0.9730\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.1837 - accuracy: 0.9452 - val_loss: 0.8396 - val_accuracy: 0.9730\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.1047 - accuracy: 0.9452 - val_loss: 0.8323 - val_accuracy: 0.9730\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 1.0927 - accuracy: 0.9452 - val_loss: 0.8032 - val_accuracy: 0.9730\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.0900 - accuracy: 0.9521 - val_loss: 0.8045 - val_accuracy: 0.9730\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 1.0834 - accuracy: 0.9452 - val_loss: 0.8127 - val_accuracy: 0.9730\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 1.0898 - accuracy: 0.9521 - val_loss: 0.7824 - val_accuracy: 0.9730\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 1.2136 - accuracy: 0.9384 - val_loss: 0.7539 - val_accuracy: 0.9730\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 1.2510 - accuracy: 0.9452 - val_loss: 0.9485 - val_accuracy: 0.9730\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 1.1917 - accuracy: 0.9658 - val_loss: 0.7357 - val_accuracy: 0.9730\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 1.4635 - accuracy: 0.9315 - val_loss: 0.7075 - val_accuracy: 0.9730\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 1.0832 - accuracy: 0.9521 - val_loss: 0.9901 - val_accuracy: 0.9730\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.9901 - accuracy: 0.9730\n",
            "Test accuracy: 0.9729729890823364\n"
          ]
        }
      ]
    }
  ]
}